{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YShw7vbvU1ne"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from statsmodels.tsa.stattools import adfuller, acf, pacf, q_stat\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(action='ignore', category='FutureWarning')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions\n",
        "def check_stationarity(returns):\n",
        "    \"\"\"\n",
        "    Perform Augmented Dickey-Fuller test to assess the stationarity of a time series.\n",
        "\n",
        "    Parameters:\n",
        "    - time_series: Pandas Series. The time series to be tested.\n",
        "\n",
        "    Returns:\n",
        "    - result: Dictionary containing the test statistic, p-value, critical values,\n",
        "      and the best lag based on BIC for an AR model if the series is stationary.\n",
        "    \"\"\"\n",
        "    # Drop NaN values which can occur after differencing\n",
        "    time_series = returns.dropna()\n",
        "    # Perform ADF test\n",
        "    adf_test = adfuller(time_series)\n",
        "    result = {\n",
        "        'ADF Statistic': adf_test[0],\n",
        "        'p-value': adf_test[1],\n",
        "        'Critical Values': adf_test[4],\n",
        "        'Used Lag': adf_test[2],\n",
        "        'Number of Observations': adf_test[3]\n",
        "    }\n",
        "\n",
        "    # Display the results\n",
        "    print(f'ADF Statistic: {result[\"ADF Statistic\"]}')\n",
        "    print(f'p-value: {result[\"p-value\"]}')\n",
        "    for key, value in result['Critical Values'].items():\n",
        "        print(f'Critical Value ({key}): {value}')\n",
        "\n",
        "    # Assess stationarity based on the p-value\n",
        "    if result[\"p-value\"] > 0.05:\n",
        "        print(\"The time series is likely non-stationary.\")\n",
        "    else:\n",
        "        print(\"The time series is likely stationary.\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def find_best_lag_and_rho_for_ar(returns):\n",
        "    \"\"\"\n",
        "    Fit an AutoRegressive (AR) model to find the best lag using BIC and get the rho values.\n",
        "\n",
        "    Parameters:\n",
        "    - time_series: Pandas Series. The time series for which to fit the AR model.\n",
        "\n",
        "    Returns:\n",
        "    - best_lag: The best number of lags for the AR model.\n",
        "    - rho_values: List of rho values up to the best lag.\n",
        "    \"\"\"\n",
        "    best_lag = 0\n",
        "    best_bic = np.inf\n",
        "\n",
        "    # Iterate over possible lag values to find the best BIC\n",
        "    for lag in range(1, 31):  # Adjust the range based on expected number of lags\n",
        "        model = AutoReg(returns, lags=lag)\n",
        "        results = model.fit()\n",
        "        bic = results.bic\n",
        "        if bic < best_bic:\n",
        "            best_bic = bic\n",
        "            best_lag = lag\n",
        "\n",
        "    # Get the rho values for lags up to the best lag\n",
        "    acf_values = acf(returns, nlags=best_lag)\n",
        "    rho_values = acf_values[1:best_lag+1].tolist()\n",
        "\n",
        "    return best_lag, rho_values\n",
        "\n",
        "\n",
        "def determine_rho_and_lag(time_series, nlags=20, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Determine the rho values and best lag for unsmoothing a time series.\n",
        "\n",
        "    Parameters:\n",
        "    - time_series: Pandas Series containing the time series data.\n",
        "    - nlags: Number of lags to consider for ACF and PACF.\n",
        "    - alpha: Significance level for statistical significance of autocorrelations.\n",
        "\n",
        "    Returns:\n",
        "    - rho_values: Significant autocorrelation coefficients.\n",
        "    - best_lag: The lag with the highest significant autocorrelation.\n",
        "    \"\"\"\n",
        "    # Ensure time_series is a Series\n",
        "    if isinstance(time_series, pd.DataFrame):\n",
        "        if time_series.shape[1] == 1:\n",
        "            time_series = time_series.iloc[:, 0]\n",
        "        else:\n",
        "            raise ValueError(\"DataFrame must have only one column\")\n",
        "\n",
        "    # Compute ACF and PACF\n",
        "    acf_values, acf_confint = acf(time_series, nlags=nlags, alpha=alpha, fft=False)\n",
        "    pacf_values, pacf_confint = pacf(time_series, nlags=nlags, alpha=alpha, method='ols')\n",
        "\n",
        "    # Identify significant lags\n",
        "    significant_lags = np.where((acf_confint[:, 0] > acf_values) | (acf_confint[:, 1] < acf_values))[0]\n",
        "    rho_values = acf_values[significant_lags]\n",
        "    best_lag = significant_lags[0] if significant_lags.size > 0 else None\n",
        "\n",
        "    return rho_values, best_lag\n",
        "\n",
        "\n",
        "def unsmooth_returns(returns_series, rho, order=1):\n",
        "    \"\"\"\n",
        "    Adjusts a series of returns for smoothing as per Geltner (1993) and Okunev & White (2003).\n",
        "\n",
        "    Parameters:\n",
        "    - returns_series: Pandas Series containing the smoothed returns.\n",
        "    - rho: List of autocorrelation coefficients for each lag.\n",
        "    - order: The order of the autocorrelation.\n",
        "\n",
        "    Returns:\n",
        "    - unsmoothed_returns: The unsmoothed returns series.\n",
        "    \"\"\"\n",
        "    if not isinstance(rho, list) or len(rho) < order:\n",
        "        raise ValueError(\"rho must be a list with length equal to the specified order\")\n",
        "\n",
        "    unsmoothed_returns = returns_series.copy()\n",
        "    for i in range(1, order + 1):\n",
        "        unsmoothed_returns += (rho[i - 1] / (1 - rho[i - 1])) * (returns_series - returns_series.shift(i))\n",
        "\n",
        "    # Drop NaN values resulted from shifting\n",
        "    unsmoothed_returns = unsmoothed_returns.dropna()\n",
        "\n",
        "    return unsmoothed_returns\n",
        "\n"
      ],
      "metadata": {
        "id": "IfYmKHMXVytb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "df_hfri = pd.read_csv(r'index_ror_perf_download-2899_1705242702.csv', index_col=0, parse_dates=True)\n",
        "# set the datetime frequency to monthly\n",
        "df_hfri = df_hfri.asfreq('M')\n"
      ],
      "metadata": {
        "id": "_VEyTmN9Vk0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test for stationarity\n",
        "stationarity_results = check_stationarity(df_hfri)"
      ],
      "metadata": {
        "id": "DSEG671fV3Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the time series is stationary, find the best lag for the AR model\n",
        "best_lag, rho_values = find_best_lag_and_rho_for_ar(df_hfri)\n",
        "print(f\"Best Lag: {best_lag}\")\n",
        "print(f\"Rho Values: {rho_values}\")"
      ],
      "metadata": {
        "id": "cK_U2mGEWU_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the autocorrelations\n",
        "unsmoothed_series = unsmooth_returns(df_hfri, rho_values, order=best_lag)"
      ],
      "metadata": {
        "id": "VvDkuSCzXkB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the volatility and annualized returns\n",
        "reported_vol = np.round((df_hfri.iloc[:, 0].std() * np.sqrt(12)) * 100, 2)\n",
        "adjusted_vol = np.round((unsmoothed_series.iloc[:, 0].std() * np.sqrt(12)) * 100, 2)\n",
        "\n",
        "reported_annualized_return = (ia.annualize_returns(df_hfri, 'M').iloc[:, 0].values[0])\n",
        "actual_annualized_return = (ia.annualize_returns(unsmoothed_series, 'M').iloc[:, 0].values[0])\n",
        "\n",
        "print(f'Annualized Volatility Before Smoothing: {reported_vol}')\n",
        "print(f'Annualized Volatility After Adjustment: {adjusted_vol}')\n",
        "\n",
        "print(f\"Annualized Return Before Smoothing: {reported_annualized_return}\")\n",
        "print(f\"Annualized Return After Adjustment: {actual_annualized_return}\")"
      ],
      "metadata": {
        "id": "fBub6z7SXmVR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}